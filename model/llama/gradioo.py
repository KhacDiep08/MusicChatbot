import gradio as gr
import json
import time
from pipelinee import MusicChatbotPipeline, PipelineConfig

class MusicChatbotGUI:
    def __init__(self, config: PipelineConfig = None):
        self.config = config or PipelineConfig()
        self.pipeline = MusicChatbotPipeline(self.config)
                
    def chat_response(self, message, history, use_rag, temperature, max_tokens):
        if not message.strip():
            return history, history, " Vui l√≤ng nh·∫≠p c√¢u h·ªèi!"
        
        start_time = time.time()
        try:
            original_rag_state = self.pipeline.conversation_manager.rag
            if not use_rag:
                self.pipeline.conversation_manager.rag = None
                
            try:
                response = self.pipeline.conversation_manager.generate_response(
                    message, 
                    max_new_tokens=max_tokens,
                    temperature=temperature
                )
                response_time = time.time() - start_time
                history.append([message, response])
                status = f" ƒê√£ tr·∫£ l·ªùi trong {response_time:.2f}s | RAG: {'B·∫≠t' if use_rag else 'T·∫Øt'}"
                return history, history, status
            finally:
                self.pipeline.conversation_manager.rag = original_rag_state
        except Exception as e:
            error_msg = f" L·ªói: {str(e)}"
            history.append([message, f"Xin l·ªói, ƒë√£ x·∫£y ra l·ªói: {str(e)}"])
            return history, history, error_msg

    def clear_conversation(self):
        self.pipeline.conversation_manager.clear_history()
        return [], [], " ƒê√£ x√≥a l·ªãch s·ª≠ h·ªôi tho·∫°i"

    def get_stats(self):
        stats = self.pipeline.get_stats()
        rag_size = len(self.pipeline.retriever.db) if self.pipeline.retriever else 0
        return f"""
        üìä **Th·ªëng k√™ Chat:**
        - T·ªïng s·ªë c√¢u h·ªèi: {stats['total_queries']}
        - Th·ªùi gian tr·∫£ l·ªùi TB: {stats['avg_time']}s
        - S·ªë l∆∞·ª£t h·ªôi tho·∫°i: {stats['turns']}
        - RAG database: {rag_size} b√†i h√°t
        - Model: {self.config.model_name.split('/')[-1]}
        - LoRA: {'B·∫≠t' if self.config.use_lora else 'T·∫Øt'}
        """

    def export_conversation(self, history):
        if not history:
            return None
        filename = self.pipeline.save_conversation()
        return filename

    def create_interface(self):
        css = """
        .gradio-container {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }
        .chat-message {
            padding: 10px;
            margin: 5px;
            border-radius: 10px;
        }
        """
        
        with gr.Blocks(css=css, title="üéµ Music Chatbot", theme=gr.themes.Soft()) as demo:
            gr.Markdown("""
            # üéµ Music Chatbot Assistant
            ### Tr·ª£ l√Ω AI chuy√™n v·ªÅ √¢m nh·∫°c v·ªõi c√¥ng ngh·ªá RAG + Llama-2
            üí° **H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng:**
            - H·ªèi v·ªÅ b√†i h√°t, ca sƒ©, th·ªÉ lo·∫°i nh·∫°c
            - B·∫≠t RAG ƒë·ªÉ t√¨m ki·∫øm trong c∆° s·ªü d·ªØ li·ªáu
            - ƒêi·ªÅu ch·ªânh tham s·ªë ƒë·ªÉ t√πy ch·ªânh ph·∫£n h·ªìi
            """)
            
            with gr.Row():
                with gr.Column(scale=2):
                    chatbot = gr.Chatbot(height=500, label=" Cu·ªôc tr√≤ chuy·ªán", bubble_full_width=False)
                    with gr.Row():
                        msg = gr.Textbox(
                            placeholder="H·ªèi g√¨ ƒë√≥ v·ªÅ √¢m nh·∫°c... (VD: 'Ed Sheeran c√≥ nh·ªØng b√†i h√°t n√†o?')",
                            label="Tin nh·∫Øn", lines=2, scale=4
                        )
                        send_btn = gr.Button(" G·ª≠i", variant="primary", scale=1)
                    
                    with gr.Row():
                        gr.Examples(
                            examples=[
                                ["T√¨m b√†i h√°t v·ªÅ t√¨nh y√™u"],
                                ["Ed Sheeran c√≥ nh·ªØng b√†i h√°t n√†o?"],
                                ["Th·ªÉ lo·∫°i pop c√≥ g√¨ hay?"],
                                ["G·ª£i √Ω b√†i h√°t bu·ªìn"],
                            ],
                            inputs=msg,
                            label="üí° C√¢u h·ªèi m·∫´u"
                        )
                
                with gr.Column(scale=1):
                    gr.Markdown("### ‚öôÔ∏è C√†i ƒë·∫∑t")
                    use_rag = gr.Checkbox(label="üîç B·∫≠t RAG (Retrieval)", value=True)
                    temperature = gr.Slider(minimum=0.1, maximum=1.0, value=0.7, step=0.1, label="üå°Ô∏è Temperature")
                    max_tokens = gr.Slider(minimum=128, maximum=1024, value=512, step=128, label="üìù Max Tokens")
                    
                    gr.Markdown("### üõ†Ô∏è H√†nh ƒë·ªông")
                    clear_btn = gr.Button(" X√≥a l·ªãch s·ª≠", variant="secondary")
                    export_btn = gr.Button(" Xu·∫•t cu·ªôc tr√≤ chuy·ªán")
                    
                    gr.Markdown("###  Th·ªëng k√™")
                    stats_display = gr.Markdown(self.get_stats())
                    refresh_stats_btn = gr.Button(" C·∫≠p nh·∫≠t th·ªëng k√™")
            
            status = gr.Textbox(label="Tr·∫°ng th√°i", interactive=False, value=" S·∫µn s√†ng chat!")
            history_state = gr.State([])
            
            def respond(message, history, use_rag, temperature, max_tokens):
                return self.chat_response(message, history, use_rag, temperature, max_tokens)
            
            send_btn.click(respond, inputs=[msg, history_state, use_rag, temperature, max_tokens],
                           outputs=[chatbot, history_state, status]).then(lambda: "", outputs=[msg])
            
            msg.submit(respond, inputs=[msg, history_state, use_rag, temperature, max_tokens],
                       outputs=[chatbot, history_state, status]).then(lambda: "", outputs=[msg])
            
            clear_btn.click(lambda: self.clear_conversation(),
                            outputs=[chatbot, history_state, status])
            
            export_btn.click(self.export_conversation, inputs=[history_state],
                             outputs=[gr.File(label="üìÅ File ƒë√£ xu·∫•t")])
            
            refresh_stats_btn.click(self.get_stats, outputs=[stats_display])
            
        return demo

def main():
    config = PipelineConfig.load("config.json")
    gui = MusicChatbotGUI(config)
    demo = gui.create_interface()
    demo.launch(share=True, server_name="0.0.0.0", server_port=7860, show_error=True, debug=True)

if __name__ == "__main__":
    main()
