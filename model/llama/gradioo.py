import gradio as gr
import json
import time
from pipelinee import MusicChatbotPipeline, PipelineConfig

class MusicChatbotGUI:
    def __init__(self, config: PipelineConfig = None):
        self.config = config or PipelineConfig()
        self.pipeline = MusicChatbotPipeline(self.config)
                
    def chat_response(self, message, history, use_rag, temperature, max_tokens):
        if not message.strip():
            return history, history, "âš ï¸ Vui lÃ²ng nháº­p cÃ¢u há»i!"
        
        start_time = time.time()
        try:
            original_rag_state = self.pipeline.conversation_manager.rag
            if not use_rag:
                self.pipeline.conversation_manager.rag = None
                
            try:
                response = self.pipeline.conversation_manager.generate_response(
                    message, 
                    max_new_tokens=max_tokens,
                    temperature=temperature
                )
                response_time = time.time() - start_time
                history.append([message, response])
                status = f"âœ… ÄÃ£ tráº£ lá»i trong {response_time:.2f}s | RAG: {'Báº­t' if use_rag else 'Táº¯t'}"
                return history, history, status
            finally:
                self.pipeline.conversation_manager.rag = original_rag_state
        except Exception as e:
            error_msg = f"âŒ Lá»—i: {str(e)}"
            history.append([message, f"Xin lá»—i, Ä‘Ã£ xáº£y ra lá»—i: {str(e)}"])
            return history, history, error_msg

    def clear_conversation(self):
        self.pipeline.conversation_manager.clear_history()
        return [], [], "ğŸ”„ ÄÃ£ xÃ³a lá»‹ch sá»­ há»™i thoáº¡i"

    def get_stats(self):
        stats = self.pipeline.get_stats()
        rag_size = len(self.pipeline.retriever.db) if self.pipeline.retriever else 0
        return f"""
        ğŸ“Š **Thá»‘ng kÃª Chat:**
        - Tá»•ng sá»‘ cÃ¢u há»i: {stats['total_queries']}
        - Thá»i gian tráº£ lá»i TB: {stats['avg_time']}s
        - Sá»‘ lÆ°á»£t há»™i thoáº¡i: {stats['turns']}
        - RAG database: {rag_size} bÃ i hÃ¡t
        - Model: {self.config.model_name.split('/')[-1]}
        - LoRA: {'Báº­t' if self.config.use_lora else 'Táº¯t'}
        """

    def export_conversation(self, history):
        if not history:
            return None
        filename = self.pipeline.save_conversation()
        return filename

    def create_interface(self):
        css = """
        .gradio-container {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }
        .chat-message {
            padding: 10px;
            margin: 5px;
            border-radius: 10px;
        }
        """
        
        with gr.Blocks(css=css, title="ğŸµ Music Chatbot", theme=gr.themes.Soft()) as demo:
            gr.Markdown("""
            # ğŸµ Music Chatbot Assistant
            ### Trá»£ lÃ½ AI chuyÃªn vá» Ã¢m nháº¡c vá»›i cÃ´ng nghá»‡ RAG + Llama-2
            ğŸ’¡ **HÆ°á»›ng dáº«n sá»­ dá»¥ng:**
            - Há»i vá» bÃ i hÃ¡t, ca sÄ©, thá»ƒ loáº¡i nháº¡c
            - Báº­t RAG Ä‘á»ƒ tÃ¬m kiáº¿m trong cÆ¡ sá»Ÿ dá»¯ liá»‡u
            - Äiá»u chá»‰nh tham sá»‘ Ä‘á»ƒ tÃ¹y chá»‰nh pháº£n há»“i
            """)
            
            with gr.Row():
                with gr.Column(scale=2):
                    chatbot = gr.Chatbot(height=500, label="ğŸ¤– Cuá»™c trÃ² chuyá»‡n", bubble_full_width=False)
                    with gr.Row():
                        msg = gr.Textbox(
                            placeholder="Há»i gÃ¬ Ä‘Ã³ vá» Ã¢m nháº¡c... (VD: 'Ed Sheeran cÃ³ nhá»¯ng bÃ i hÃ¡t nÃ o?')",
                            label="Tin nháº¯n", lines=2, scale=4
                        )
                        send_btn = gr.Button("ğŸ“¤ Gá»­i", variant="primary", scale=1)
                    
                    with gr.Row():
                        gr.Examples(
                            examples=[
                                ["TÃ¬m bÃ i hÃ¡t vá» tÃ¬nh yÃªu"],
                                ["Ed Sheeran cÃ³ nhá»¯ng bÃ i hÃ¡t nÃ o?"],
                                ["Thá»ƒ loáº¡i pop cÃ³ gÃ¬ hay?"],
                                ["Gá»£i Ã½ bÃ i hÃ¡t buá»“n"],
                            ],
                            inputs=msg,
                            label="ğŸ’¡ CÃ¢u há»i máº«u"
                        )
                
                with gr.Column(scale=1):
                    gr.Markdown("### âš™ï¸ CÃ i Ä‘áº·t")
                    use_rag = gr.Checkbox(label="ğŸ” Báº­t RAG (Retrieval)", value=True)
                    temperature = gr.Slider(minimum=0.1, maximum=1.0, value=0.7, step=0.1, label="ğŸŒ¡ï¸ Temperature")
                    max_tokens = gr.Slider(minimum=128, maximum=1024, value=512, step=128, label="ğŸ“ Max Tokens")
                    
                    gr.Markdown("### ğŸ› ï¸ HÃ nh Ä‘á»™ng")
                    clear_btn = gr.Button("ğŸ—‘ï¸ XÃ³a lá»‹ch sá»­", variant="secondary")
                    export_btn = gr.Button("ğŸ’¾ Xuáº¥t cuá»™c trÃ² chuyá»‡n")
                    
                    gr.Markdown("### ğŸ“Š Thá»‘ng kÃª")
                    stats_display = gr.Markdown(self.get_stats())
                    refresh_stats_btn = gr.Button("ğŸ”„ Cáº­p nháº­t thá»‘ng kÃª")
            
            status = gr.Textbox(label="Tráº¡ng thÃ¡i", interactive=False, value="âœ… Sáºµn sÃ ng chat!")
            history_state = gr.State([])
            
            def respond(message, history, use_rag, temperature, max_tokens):
                return self.chat_response(message, history, use_rag, temperature, max_tokens)
            
            send_btn.click(respond, inputs=[msg, history_state, use_rag, temperature, max_tokens],
                           outputs=[chatbot, history_state, status]).then(lambda: "", outputs=[msg])
            
            msg.submit(respond, inputs=[msg, history_state, use_rag, temperature, max_tokens],
                       outputs=[chatbot, history_state, status]).then(lambda: "", outputs=[msg])
            
            clear_btn.click(lambda: self.clear_conversation(),
                            outputs=[chatbot, history_state, status])
            
            export_btn.click(self.export_conversation, inputs=[history_state],
                             outputs=[gr.File(label="ğŸ“ File Ä‘Ã£ xuáº¥t")])
            
            refresh_stats_btn.click(self.get_stats, outputs=[stats_display])
            
        return demo

def main():
    config = PipelineConfig.load("config.json")
    gui = MusicChatbotGUI(config)
    demo = gui.create_interface()
    demo.launch(share=True, server_name="0.0.0.0", server_port=7860, show_error=True, debug=True)

if __name__ == "__main__":
    main()
