import gradio as gr
import json
import time
from pipeline import MusicChatbotPipeline, PipelineConfig

class MusicChatbotGUI:
    def __init__(self, config: PipelineConfig = None):
        # Initialize pipeline vá»›i config
        self.config = config or PipelineConfig()
        self.pipeline = MusicChatbotPipeline(self.config)
        
        # Backup pipeline for comparison
        config_no_rag = PipelineConfig(**{**self.config.__dict__, 'use_rag': False})
        self.pipeline_no_rag = MusicChatbotPipeline(config_no_rag)
        
    def chat_response(self, message, history, use_rag, temperature, max_tokens):
        """Generate chatbot response with timing"""
        if not message.strip():
            return history, history, "âš ï¸ Vui lÃ²ng nháº­p cÃ¢u há»i!"
        
        start_time = time.time()
        
        try:
            # Choose conversation manager
            conv_manager = self.conv_with_rag if use_rag else self.conv_without_rag
            
            # Generate response
            response = conv_manager.generate_response(message)
            
            # Calculate timing
            response_time = time.time() - start_time
            self.total_queries += 1
            self.avg_response_time = (self.avg_response_time * (self.total_queries - 1) + response_time) / self.total_queries
            
            # Update history
            history.append([message, response])
            
            # Status message
            status = f"âœ… ÄÃ£ tráº£ lá»i trong {response_time:.2f}s | RAG: {'Báº­t' if use_rag else 'Táº¯t'}"
            
            return history, history, status
            
        except Exception as e:
            error_msg = f"âŒ Lá»—i: {str(e)}"
            history.append([message, f"Xin lá»—i, Ä‘Ã£ xáº£y ra lá»—i: {str(e)}"])
            return history, history, error_msg

    def clear_conversation(self):
        """Clear conversation history"""
        self.pipeline.conversation_manager.conversation_history = []
        self.pipeline_no_rag.conversation_manager.conversation_history = []
        return [], [], "ğŸ”„ ÄÃ£ xÃ³a lá»‹ch sá»­ há»™i thoáº¡i"

    def get_stats(self):
        """Get chatbot statistics"""
        stats = self.pipeline.get_stats()
        rag_size = len(self.pipeline.retriever.db) if self.pipeline.retriever else 0
        
        return f"""
        ğŸ“Š **Thá»‘ng kÃª Chat:**
        - Tá»•ng sá»‘ cÃ¢u há»i: {stats['total_queries']}
        - Thá»i gian tráº£ lá»i TB: {stats['avg_time']}s
        - Sá»‘ lÆ°á»£t há»™i thoáº¡i: {stats['turns']}
        - RAG database: {rag_size} bÃ i hÃ¡t
        - Model: {self.config.model_name.split('/')[-1]}
        - LoRA: {'Báº­t' if self.config.use_lora else 'Táº¯t'}
        """

    def export_conversation(self, history):
        """Export conversation to JSON"""
        if not history:
            return None
            
        # Use pipeline's save method
        filename = self.pipeline.save_conversation()
        return filename

    def create_interface(self):
        """Create Gradio interface"""
        
        # Custom CSS
        css = """
        .gradio-container {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }
        .chat-message {
            padding: 10px;
            margin: 5px;
            border-radius: 10px;
        }
        """
        
        with gr.Blocks(css=css, title="ğŸµ Music Chatbot", theme=gr.themes.Soft()) as demo:
            
            # Header
            gr.Markdown("""
            # ğŸµ Music Chatbot Assistant
            ### Trá»£ lÃ½ AI chuyÃªn vá» Ã¢m nháº¡c vá»›i cÃ´ng nghá»‡ RAG + Llama-2
            
            ğŸ’¡ **HÆ°á»›ng dáº«n sá»­ dá»¥ng:**
            - Há»i vá» bÃ i hÃ¡t, ca sÄ©, thá»ƒ loáº¡i nháº¡c
            - Báº­t RAG Ä‘á»ƒ tÃ¬m kiáº¿m trong cÆ¡ sá»Ÿ dá»¯ liá»‡u
            - Äiá»u chá»‰nh tham sá»‘ Ä‘á»ƒ tÃ¹y chá»‰nh pháº£n há»“i
            """)
            
            with gr.Row():
                with gr.Column(scale=2):
                    # Main chatbot interface
                    chatbot = gr.Chatbot(
                        height=500,
                        label="ğŸ¤– Cuá»™c trÃ² chuyá»‡n",
                        bubble_full_width=False
                    )
                    
                    with gr.Row():
                        msg = gr.Textbox(
                            placeholder="Há»i gÃ¬ Ä‘Ã³ vá» Ã¢m nháº¡c... (VD: 'Ed Sheeran cÃ³ nhá»¯ng bÃ i hÃ¡t nÃ o?')",
                            label="Tin nháº¯n",
                            lines=2,
                            scale=4
                        )
                        send_btn = gr.Button("ğŸ“¤ Gá»­i", variant="primary", scale=1)
                    
                    # Quick examples
                    with gr.Row():
                        gr.Examples(
                            examples=[
                                ["TÃ¬m bÃ i hÃ¡t vá» tÃ¬nh yÃªu"],
                                ["Ed Sheeran cÃ³ nhá»¯ng bÃ i hÃ¡t nÃ o?"],
                                ["Thá»ƒ loáº¡i pop cÃ³ gÃ¬ hay?"],
                                ["Gá»£i Ã½ bÃ i hÃ¡t buá»“n"],
                                ["Nháº¡c sÄ© Trá»‹nh CÃ´ng SÆ¡n viáº¿t nhá»¯ng gÃ¬?"]
                            ],
                            inputs=msg,
                            label="ğŸ’¡ CÃ¢u há»i máº«u"
                        )
                
                with gr.Column(scale=1):
                    # Settings panel
                    gr.Markdown("### âš™ï¸ CÃ i Ä‘áº·t")
                    
                    use_rag = gr.Checkbox(
                        label="ğŸ” Báº­t RAG (Retrieval)",
                        value=True,
                        info="TÃ¬m kiáº¿m trong cÆ¡ sá»Ÿ dá»¯ liá»‡u nháº¡c"
                    )
                    
                    temperature = gr.Slider(
                        minimum=0.1,
                        maximum=1.0,
                        value=0.7,
                        step=0.1,
                        label="ğŸŒ¡ï¸ Temperature",
                        info="Äá»™ sÃ¡ng táº¡o (cao = ngáº«u nhiÃªn hÆ¡n)"
                    )
                    
                    max_tokens = gr.Slider(
                        minimum=128,
                        maximum=1024,
                        value=512,
                        step=128,
                        label="ğŸ“ Max Tokens",
                        info="Äá»™ dÃ i tá»‘i Ä‘a cá»§a pháº£n há»“i"
                    )
                    
                    # Action buttons
                    gr.Markdown("### ğŸ› ï¸ HÃ nh Ä‘á»™ng")
                    clear_btn = gr.Button("ğŸ—‘ï¸ XÃ³a lá»‹ch sá»­", variant="secondary")
                    export_btn = gr.Button("ğŸ’¾ Xuáº¥t cuá»™c trÃ² chuyá»‡n")
                    
                    # Stats
                    gr.Markdown("### ğŸ“Š Thá»‘ng kÃª")
                    stats_display = gr.Markdown(self.get_stats())
                    refresh_stats_btn = gr.Button("ğŸ”„ Cáº­p nháº­t thá»‘ng kÃª")
            
            # Status bar
            status = gr.Textbox(
                label="Tráº¡ng thÃ¡i",
                interactive=False,
                value="âœ… Sáºµn sÃ ng chat!"
            )
            
            # Hidden state for history
            history_state = gr.State([])
            
            # Event handlers
            def respond(message, history, use_rag, temperature, max_tokens):
                return self.chat_response(message, history, use_rag, temperature, max_tokens)
            
            # Send message
            send_btn.click(
                respond,
                inputs=[msg, history_state, use_rag, temperature, max_tokens],
                outputs=[chatbot, history_state, status]
            ).then(
                lambda: "",  # Clear input
                outputs=[msg]
            )
            
            # Enter key
            msg.submit(
                respond,
                inputs=[msg, history_state, use_rag, temperature, max_tokens],
                outputs=[chatbot, history_state, status]
            ).then(
                lambda: "",
                outputs=[msg]
            )
            
            # Clear conversation
            clear_btn.click(
                lambda: ([], [], "ğŸ”„ ÄÃ£ xÃ³a lá»‹ch sá»­ há»™i thoáº¡i"),
                outputs=[chatbot, history_state, status]
            ).then(
                self.clear_conversation
            )
            
            # Export conversation
            export_btn.click(
                self.export_conversation,
                inputs=[history_state],
                outputs=[gr.File(label="ğŸ“ File Ä‘Ã£ xuáº¥t")]
            )
            
            # Refresh stats
            refresh_stats_btn.click(
                self.get_stats,
                outputs=[stats_display]
            )
            
        return demo

def main():
    # Load config hoáº·c dÃ¹ng default
    config = PipelineConfig.load("config.json")  # Auto fallback to default náº¿u khÃ´ng cÃ³
    
    # Initialize GUI vá»›i config
    gui = MusicChatbotGUI(config)
    
    # Create and launch interface
    demo = gui.create_interface()
    
    # Launch with options
    demo.launch(
        share=True,  # Táº¡o public link
        server_name="0.0.0.0",  # Accept tá»« má»i IP
        server_port=7860,  # Port máº·c Ä‘á»‹nh
        show_error=True,  # Hiá»‡n lá»—i chi tiáº¿t
        debug=True  # Debug mode
    )

if __name__ == "__main__":
    main()